#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        New clean deployment using latest Zeppelin images.

    Result:

        Works in the end .. but not seamlessly.
        Good enough for now, got other things to chase.
        Will need to come back later to get this fixed.


# -----------------------------------------------------
# Update the project name.
#[user@desktop]

    cloudname=gaia-prod

    sed -i '
        s/^\(AGLAIS_CLOUD\)=.*$/\1='${cloudname:?}'/
        ' "${HOME}/aglais.env"


# -----------------------------------------------------
# Modify the Zeppelin image version in our Helm charts.
#[user@desktop]

    buildtag=20201227-051927-debian-9-java-8

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE:?}"

        sed -i '
            s/^\(zeppelin_server_image\):.*$/\1: "aglais\/zeppelin-dev:'${buildtag:?}'"/
            s/^\(zeppelin_worker_image\):.*$/\1: "aglais\/zeppelin-dev:'${buildtag:?}'"/
            ' experiments/kubernetes/helm/tools/zeppelin/values.yaml

    popd


# -----------------------------------------------------
# Create a new container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name kubernator \
        --hostname kubernator \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/experiments/openstack:/openstack:ro,z" \
        --volume "${AGLAIS_CODE:?}/experiments/kubernetes:/kubernetes:rw,z" \
        atolmis/openstack-client:latest \
        bash


# -----------------------------------------------------
# Delete everything.
#[root@kubernator]

    /openstack/bin/delete-all.sh \
        "${cloudname:?}"

    >   ....
    >   ....


# -----------------------------------------------------
# Run the main Kubernetes deployment.
#[root@kubernator]

    buildname="aglais-$(date '+%Y%m%d')"
    namespace=${buildname,,}

    /kubernetes/bin/create-all.sh \
        "${cloudname:?}" \
        "${buildname:?}" \
        "${namespace:?}"

    >   ....
    >   ....
    >   Installing dashboard Helm chart
    >   Namespace [aglais-20210111]
    >   Dash host [valeria.metagrid.xyz]
    >   Getting updates for unmanaged Helm repositories...
    >   ...Successfully got an update from the "https://kubernetes.github.io/dashboard" chart repository
    >   Saving 1 charts
    >   Downloading kubernetes-dashboard from repo https://kubernetes.github.io/dashboard
    >   Deleting outdated charts
    >   Release "aglais-dashboard" does not exist. Installing it now.
    >   Error: Internal error occurred: failed calling webhook "validate.nginx.ingress.kubernetes.io": Post https://aglais-ingress-nginx-controller-admission.aglais-20210111.svc:443/networking/v1beta1/ingresses?timeout=10s: dial tcp 10.254.190.227:443: connect: connection refused
    >   ....
    >   ....

    #
    # Mysterious Dashboard validation error is back :-(
    #


# -----------------------------------------------------
# Get the ServiceAccount token.
#[root@kubernator]

    secretname=$(
        kubectl \
            --output json \
            --namespace "${namespace:?}" \
            get ServiceAccount \
                "aglais-dashboard-kubernetes-dashboard" \
        | jq -r '.secrets[0].name'
        )

    kubectl \
        --output json \
        --namespace "${namespace:?}" \
        get Secret \
            "${secretname:?}" \
    | jq -r '.data.token | @base64d'


    >   ....
    >   ....


# -----------------------------------------------------
# Get the Ingress address.
#[root@kubernator]

    kubectl \
        --namespace "${namespace:?}" \
        get Ingress

    >   No resources found in aglais-20210111 namespace.

    #
    # Our main script exited when the Dashboard deploy failed
    # because we have 'exit on error' set on the main script.
    # So it didn't add Zeppelin or Drupal, hence no Ingress
    # resources were created ....
    #

    #
    # Technically nice and accurate .. but it means we
    # are hung up on the Dashboard deployment.
    #


# -----------------------------------------------------
# -----------------------------------------------------
# Remove the 'exit on error' hook and try again.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    gedit ${AGLAIS_CODE:?}/experiments/kubernetes/bin/create-all.sh

    ~   #   set -eu
    ~   #   set -o pipefail


# -----------------------------------------------------
# Create a new container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name kubernator \
        --hostname kubernator \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/experiments/openstack:/openstack:ro,z" \
        --volume "${AGLAIS_CODE:?}/experiments/kubernetes:/kubernetes:rw,z" \
        atolmis/openstack-client:latest \
        bash


# -----------------------------------------------------
# Delete everything.
#[root@kubernator]

    /openstack/bin/delete-all.sh \
        "${cloudname:?}"

    >   ....
    >   ....


# -----------------------------------------------------
# Run the main Kubernetes deployment.
#[root@kubernator]

    buildname="aglais-$(date '+%Y%m%d')"
    namespace=${buildname,,}

    /kubernetes/bin/create-all.sh \
        "${cloudname:?}" \
        "${buildname:?}" \
        "${namespace:?}"


    >   ....
    >   ....
    >   Installing dashboard Helm chart
    >   Namespace [aglais-20210111]
    >   Dash host [valeria.metagrid.xyz]
    >   Getting updates for unmanaged Helm repositories...
    >   ...Successfully got an update from the "https://kubernetes.github.io/dashboard" chart repository
    >   Saving 1 charts
    >   Downloading kubernetes-dashboard from repo https://kubernetes.github.io/dashboard
    >   Deleting outdated charts
    >   Release "aglais-dashboard" does not exist. Installing it now.
    >   Error: Internal error occurred: failed calling webhook "validate.nginx.ingress.kubernetes.io": Post https://aglais-ingress-nginx-controller-admission.aglais-20210111.svc:443/networking/v1beta1/ingresses?timeout=10s: dial tcp 10.254.240.151:443: connect: connection refused
    >   ....
    >   ....

    #
    # We still get the same error with the dashboard chart deployment,
    # but the the main script continues on to do the rest of the deployments.
    #

    #
    # Third time running today - and the error has disapeared.
    # Intermittent validation failure !!
    #


# -----------------------------------------------------
# Get the ServiceAccount token.
#[root@kubernator]

    secretname=$(
        kubectl \
            --output json \
            --namespace "${namespace:?}" \
            get ServiceAccount \
                "aglais-dashboard-kubernetes-dashboard" \
        | jq -r '.secrets[0].name'
        )

    kubectl \
        --output json \
        --namespace "${namespace:?}" \
        get Secret \
            "${secretname:?}" \
    | jq -r '.data.token | @base64d'


    >   ....
    >   ....


# -----------------------------------------------------
# Get the Ingress address.
#[root@kubernator]

    kubectl \
        --namespace "${namespace:?}" \
        get Ingress

    >   NAME                      HOSTS                   ADDRESS           PORTS     AGE
    >   aglais-dashboard-kubernetes-dashboard   valeria.metagrid.xyz    128.232.227.162   80        17m
    >   zeppelin-server-ingress                 zeppelin.metagrid.xyz   128.232.227.162   80, 443   16m


# -----------------------------------------------------
# -----------------------------------------------------

    #
    # Update our DNS ..
    #


# -----------------------------------------------------
# Check the Dashboard page.
#[root@kubernator]

    curl --head --insecure "https://valeria.metagrid.xyz/"

    >   HTTP/2 200
    >   date: Mon, 11 Jan 2021 11:42:53 GMT
    >   content-type: text/html; charset=utf-8
    >   content-length: 1272
    >   accept-ranges: bytes
    >   cache-control: no-store
    >   last-modified: Thu, 03 Sep 2020 14:10:18 GMT
    >   strict-transport-security: max-age=15724800; includeSubDomains


# -----------------------------------------------------
# Check the Zeppelin page.
#[root@kubernator]

    curl --head --insecure "https://zeppelin.metagrid.xyz/"

    >   HTTP/2 200
    >   date: Mon, 11 Jan 2021 11:43:08 GMT
    >   content-type: text/html
    >   content-length: 4660
    >   access-control-allow-credentials: true
    >   access-control-allow-headers: authorization,Content-Type
    >   access-control-allow-methods: POST, GET, OPTIONS, PUT, HEAD, DELETE
    >   x-frame-options: SAMEORIGIN
    >   x-xss-protection: 1; mode=block
    >   x-content-type-options: nosniff
    >   last-modified: Sat, 26 Dec 2020 19:42:42 GMT
    >   accept-ranges: bytes
    >   strict-transport-security: max-age=15724800; includeSubDomains


# -----------------------------------------------------
# -----------------------------------------------------
# Login to Dashboard and test ...
#[user@desktop]

    firefox --new-window "https://valeria.metagrid.xyz/" &

        #
        # Yay - Dashboard works :-)
        # Intermittent validation error :-(
        #


# -----------------------------------------------------
# Login to Zeppelin and test ...
#[user@desktop]

    firefox --new-window "https://zeppelin.metagrid.xyz/" &

        #
        # Yay - Zeppelin works :-)
        #

        #
        # ... but a simple Spark task doesn't :-(
        #

        #
        # ... a simple shell task doesn't :-(
        #

    >   ....
    >   Error: failed to start container "sh": Error response from daemon: cannot join network of a non running container: b9f2f656b675f33446a2015c17a0734c20f8afbdcd69bd431c3305ca084fbe19
    >   ....


        #
        # ... and then both of them do work
        #

        #
        # Partly to do with download time for the container image,
        # but I also suspect it is partly to do with intermittent
        # network issues inside the cloud.
        #

# -----------------------------------------------------
# -----------------------------------------------------
# Mount the Gaia data in our Spark workers.
#[user@zeppelin]

# --------------------------------
%spark.conf

spark.kubernetes.executor.volumes.persistentVolumeClaim.aglais-gaia-dr2.mount.path        /data/gaia/dr2
spark.kubernetes.executor.volumes.persistentVolumeClaim.aglais-gaia-dr2.mount.readOnly    true
spark.kubernetes.executor.volumes.persistentVolumeClaim.aglais-gaia-dr2.options.claimName aglais-gaia-dr2-claim

spark.kubernetes.executor.volumes.persistentVolumeClaim.aglais-user-nch.mount.path        /user/nch
spark.kubernetes.executor.volumes.persistentVolumeClaim.aglais-user-nch.mount.readOnly    true
spark.kubernetes.executor.volumes.persistentVolumeClaim.aglais-user-nch.options.claimName aglais-user-nch-claim

spark.kubernetes.executor.volumes.persistentVolumeClaim.aglais-user-stv.mount.path        /user/stv
spark.kubernetes.executor.volumes.persistentVolumeClaim.aglais-user-stv.mount.readOnly    true
spark.kubernetes.executor.volumes.persistentVolumeClaim.aglais-user-stv.options.claimName aglais-user-stv-claim

spark.kubernetes.executor.volumes.persistentVolumeClaim.aglais-user-zrq.mount.path        /user/zrq
spark.kubernetes.executor.volumes.persistentVolumeClaim.aglais-user-zrq.mount.readOnly    false
spark.kubernetes.executor.volumes.persistentVolumeClaim.aglais-user-zrq.options.claimName aglais-user-zrq-claim


# --------------------------------
%spark.pyspark

gaia_data = sqlContext.read.parquet(
    "/data/gaia/dr2"
    )

print("DF count: ",      gaia_data.count())
print("DF partitions: ", gaia_data.rdd.getNumPartitions())

    >   DF count:  1692919135
    >   DF partitions:  5985








