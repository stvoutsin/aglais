#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#  
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

# Benchmarking the Zeppelin REST API
# ------------------------------------

# Summary of benchmarking suit:
  We use the "zdairi" Zeppelin rest client to run our benchmarks in the following way:
    - Create secrets file
    - Create notebooks.json config where we store the list of our curated notebooks. Each entry has a link to the raw json file of the Zeppelin notebook 
    
    - For each notebook:
         Fetch notebook json file store in temp folder on local machine
         Create notebook in Zeppelin instance (Create under tmp directory in Zeppelin, i.e. change name to /tmp/notebook..)
         Run notebook, and store the execution duration
         Delete notebook from Zeppelin
         Delete temporary notebook json file in local machine
    
    - Return a dictionary of the Notebook ID's and the execution duration for each 
    - As a one off, run the benchmark suite, to get the execution time for each notebook using our test prototype 
        Test prototype deployed this way: https://github.com/stvoutsin/aglais/blob/stv-ansible-deploy/notes/stv/20201102-automated-deploy.txt


# zdairi is zeppelin CLI tool which wrapper zeppelin REST API for control notebook and interpreter.
# https://pypi.org/project/zdairi/
# Benchmarking suite can be found here: https://github.com/wfau/aglais-testing



# The following was run a local machine (Ubuntu). 
# [Update] I have also tested on a remote VM which was also however an Ubuntu machine
# For the concurrent test, we need to create the users before hand in Zeppelin


# Install Python2.7 (Required by zdairi)
# user@local
# -----------------------------------
apt install python-minimal



# Clone Aglais-testing Github project
# user@local
# -----------------------------------
git clone https://github.com/wfau/aglais-testing
pushd aglais-testing



# Setup Virtualenv
# user@local
# --------------------

virtualenv --python=python2.7 mypython
source mypython/bin/activate



# Install zdairi
# (mypython) user@local
# -----------------------------

pip install zdairi



# Edit our secrets yaml files
# For a single user benchmark, we need to edit "user.yml"
# For a multi user test, we need to setup a yml for each concurrent user, numbered as: "user1.yml", "user2.yml ..."
# (mypython) user@local
# --------------------------------

nano config/zeppelin/user.yml
..
zeppelin_url: http://128.232.227.124:8080
zeppelin_auth: true
zeppelin_user: user
zeppelin_password: pass
..  





# Optional: Edit the notebooks we want to test
# By default the project comes with two notebook configuration files, one containing a single notebook for a quick test, and one with the full list of notebooks
# (mypython) user@local
# ----------------------------------------------------------------------------


nano config/notebooks/notebook.json
..
	{
	"notebooks" : [
		   {
		      "name" : "Good_astrometric_solutions_via_ML_Random_Forrest_classifier",
		      "filepath" : "https://raw.githubusercontent.com/wfau/test-notebooks/main/notebooks/Good_astrometric_solutions_via_ML_Random_Forrest_classifier.json",
		     "totaltime" : 10
		   },
		   {
		      "name" : "Mean_proper_motions_over_the_sky",
		      "filepath" : "https://raw.githubusercontent.com/wfau/test-notebooks/main/notebooks/Mean_proper_motions_over_the_sky.json",
		      "totaltime" : 10
		   },           
		   {
		      "name" : "Sky_counts_map",
		      "filepath" : "https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2FQEUJXWH/Sky_counts_map.json",
		      "totaltime" : 10
		   },           
		   {
		      "name" : "pi_calculation",
		      "filepath" : "https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2FRPC4BFS/pi_calculation.json",
		      "totaltime" : 10
		   }

	]
	}

..


# Navigate to src/
pushd src


# -- Test #1 --
# Run Single (Quick)  pi calculation test
# (mypython) user@local
# --------------------------------------------------

python3
>>> from benchmark import Benchmarker
>>> Benchmarker("../config/notebooks/notebooks_quick_pi.json", "../config/zeppelin/").run(concurrent=False, users=1)


	> Test completed after: 4.870099782943726 seconds
	{'pi_quick': {'totaltime': 4.869176864624023, 'status': 'SUCCESS'}}



# -- Test #2 --
# Run Parallel (Quick) pi calculation test
# (mypython) user@local
# ---------------------------------------------------

python3
>>> from benchmark import Benchmarker
>>> Benchmarker("../config/notebooks/notebooks_quick_pi.json", "../config/zeppelin/").run(concurrent=True, users=3)

	> Test completed after: 8.040523767471313 seconds
	[{'pi_quick': {'totaltime': 4.556694746017456, 'status': 'SUCCESS'}}, {'pi_quick': {'totaltime': 5.730893850326538, 'status': 'SUCCESS'}}, {'pi_quick': {'totaltime': 8.007708072662354, 'status': 'SUCCESS'}}]





# -- Test #3 --
# Run a Single (Full) Benchmark test
# (mypython) user@local
# ---------------------------------------------------

python3
>>> from benchmark import Benchmarker
>>> Benchmarker("../config/notebooks/notebooks_quick_pi.json", "../config/zeppelin/").run(concurrent=True, users=3)

	> Test completed after: 2559.548201084137 seconds
	{'Good_astrometric_solutions_via_ML_Random_Forrest_classifier': {'totaltime': 856.7321133613586, 'status': 'SLOW'}, 'Mean_proper_motions_over_the_sky': {'totaltime': 388.8746974468231, 'status': 'SLOW'}, 'Sky_counts_map': {'totaltime': 1161.3819754123688, 'status': 'SLOW'}, 'pi_calculation': {'totaltime': 152.5580656528473, 'status': 'SLOW'}}



# -- Test #4 -- 
# Run a Single (Long) pi calculation test
# (mypython) user@local
# --------------------------------------------------

python3
>>> from benchmark import Benchmarker
>>> Benchmarker("../config/notebooks/notebooks_quick_pi.json", "../config/zeppelin/").run(concurrent=False, users=1)
Test completed after: 153.79138469696045 seconds
{'pi_calculation': {'totaltime': 153.7909255027771, 'status': 'SLOW'}}


