
#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#


    Target:

        Run the Ansible deploy with Zeppelin included

    Result:

        Success

# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler21 \
        --hostname ansibler \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --env "clouduser=${AGLAIS_USER:?}" \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --volume "${HOME:?}/clouds-dev.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/experiments/openstack:/openstack:ro,z" \
        --volume "${AGLAIS_CODE:?}/experiments/hadoop-yarn:/hadoop-yarn:ro,z" \
        atolmis/ansible-client:latest \
        bash

# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    /openstack/bin/delete-all.sh \
        "${cloudname:?}"


	> ---- ----
	  Done

# -----------------------------------------------------
# Run the main Ansible deployment.
#[root@ansibler]

    /hadoop-yarn/bin/create-all.sh \
        "${cloudname:?}"


      > PLAY RECAP **************************************************************************************************************************************************************************************************
	gateway                    : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
	master01                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
	master02                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
	worker01                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
	worker02                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
	worker03                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
	worker04                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
	worker05                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
	worker06                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
	zeppelin                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
	/




# -----------------------------------------------------
# Run the SparkPi example from the Spark install instructtions.
# https://spark.apache.org/docs/3.0.0-preview2/running-on-yarn.html#launching-spark-on-yarn
#[root@ansibler]

    ssh master01 \
        '
        cd "${SPARK_HOME:?}"

        spark-submit \
            --class org.apache.spark.examples.SparkPi \
            --master yarn \
            --deploy-mode cluster \
            --driver-memory 1g \
            --executor-memory 1g \
            --executor-cores 1 \
            examples/jars/spark-examples*.jar \
                10
        '

        > 
	2020-11-30 19:53:01,779 INFO yarn.Client: Application report for application_1606765605611_0001 (state: FINISHED)
	2020-11-30 19:53:01,779 INFO yarn.Client: 
		 client token: N/A
		 diagnostics: N/A
		 ApplicationMaster host: worker02
		 ApplicationMaster RPC port: 33611
		 queue: default
		 start time: 1606765969650
		 final status: SUCCEEDED
		 tracking URL: http://master01:8088/proxy/application_1606765605611_0001/
		 user: fedora
	2020-11-30 19:53:01,788 INFO util.ShutdownHookManager: Shutdown hook called
	2020-11-30 19:53:01,789 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-13b76f97-13bf-4ede-9d6e-433f634363fa
	2020-11-30 19:53:01,799 INFO util.ShutdownHookManager: Deleting directory /opt/spark-2.4.7-bin-hadoop2.7/local/spark-ee04f00e-a0ff-4d40-8427-963bccd7ebea




# -----------------------------------------------------
# Login to the Zeppelinto test the Gaia DR2 mount.
#[root@ansibler]

    ssh zeppelin \
        '
        date
        hostname
        echo "----"
        df -h  /data/gaia/dr2
        '

        >
        Mon Nov 30 19:53:33 UTC 2020
	aglais-20201130-zeppelin.novalocal
	----
	Filesystem      Size  Used Avail Use% Mounted on
	ceph-fuse       512G  473G   40G  93% /data/gaia/dr2



# -----------------------------------------------------
# Login to the Zeppelin to test Nigel's mount.
#[root@ansibler]

    ssh zeppelin         '
        date
        hostname
        echo "----"
        df -h  /user/nch
        '
      
        >
        Mon Nov 30 19:53:45 UTC 2020
	aglais-20201130-zeppelin.novalocal
	----
	Filesystem      Size  Used Avail Use% Mounted on
	ceph-fuse        10T     0   10T   0% /user/nch


# -----------------------------------------------------
# Login to the Zeppelin and setup users
#[root@ansibler]

# Manual process warning! We manually setup user accounts here
# TODO: turn into automated process

ssh zeppelin

   sudo yum -y install nano
   nano /home/fedora/zeppelin-0.8.2-bin-all/conf/shiro.ini
     # Setup admin & gaiausers
   /home/fedora/zeppelin-0.8.2-bin-all/bin/zeppelin-daemon.sh restart

exit



# -----------------------------------------------------
# Try some Spark jobs via the Zeppelin GUI.
firefox http://128.232.227.243:8080/#/ &


%spark.pyspark
import random 
NUM_SAMPLES = 200000

def inside(p):
    x, y = random.random(), random.random()
    return x*x + y*y < 1

count = sc.parallelize(range(0, NUM_SAMPLES)) \
             .filter(inside).count()
print ("Pi is roughly %f" % (4.0 * count / NUM_SAMPLES))

> Pi is roughly 3.142360

# Success



# -----------------------------------------------------
# Login to the Zeppelin and setup integration with github
#[root@ansibler]

# Manual Step Warning! We need to setup github user & pass for commiting changes to our notebooks
# TODO: automate this


  ssh zeppelin \
        '
        export githubuser=user
        export githubpass=pass

        rm -rf /home/fedora/zeppelin-0.8.2-bin-all/notebook
	git clone https://${githubuser:?}:${githubpass:?}@github.com/wfau/aglais-notebooks.git /home/fedora/zeppelin-0.8.2-bin-all/notebook

	cat > "${HOME}/zeppelin-0.8.2-bin-all/notebook/.git/hooks/post-commit" << EOF
	#!/bin/sh
	git push 

	EOF

	chmod +x ${HOME}/zeppelin-0.8.2-bin-all/notebook/.git/hooks/post-commit
	/home/fedora/zeppelin-0.8.2-bin-all/bin/zeppelin-daemon.sh restart
	'

	> Cloning into '/home/fedora/zeppelin-0.8.2-bin-all/notebook'...
	  Zeppelin stop                                              [  OK  ]
	  Zeppelin start                                             [  OK  ]

# Success


# -----------------------------------------------------
# Check Zeppelin GUI again to see that Github integration worked.
firefox http://128.232.227.243:8080/#/ &

# Success, all notebooks show up correctly



# -----------------------------------------------------
# Try modifying a notebook to read Gaia from Ceph mount
firefox http://128.232.227.243:8080/#/ &

%pyspark
df = spark.read.parquet("file:///data/gaia/dr2/*.parquet").select("source_id","parallax_error").where("parallax_error is not null")
df.explain()
df.show()
df.schema


	== Physical Plan ==
	*(1) Project [source_id#2L, parallax_error#10]
	+- *(1) Filter isnotnull(parallax_error#10)
	   +- *(1) FileScan parquet [source_id#2L,parallax_error#10] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/data/gaia/dr2/part-03446-70392076-8b82-4457-8828-22069e7626e9-c000.snappy..., PartitionFilters: [], PushedFilters: [IsNotNull(parallax_error)], ReadSchema: struct<source_id:bigint,parallax_error:double>
	+-------------------+-------------------+
	|          source_id|     parallax_error|
	+-------------------+-------------------+
	|4039678872339871744| 0.7696924805050609|
	|4039662384016337024| 0.5435004501205588|
	|4039671626792835968|0.42596571385844906|
	|4039666026147249152|0.28351409607368766|
	|4039675986122456576| 0.2856491691557616|
	|4039662899409694464|  0.460774649076223|
	|4039677463587633664| 0.1194583081060792|
	|4039679323380141184| 0.6884603733194365|
	|4039676952559930112| 0.3854673772956747|
	|4039676952559916672|  0.315567173944316|


# Success



# -----------------------------------------------------
# Add Nigel's key to Zeppelin & Master Nodes
#[root@ansibler]

# Log into Zeppelin
ssh zeppelin

	# Add new user
	sudo useradd -m -d /home/nch -s /bin/bash nch


	# Create ssh directory
	sudo mkdir /home/nch/.ssh

	# Add public key
	sudo -- sh -c "echo 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDGM3u6JzlKmDQ+gc8Sb9JFtqCL650PllkvnOto8fNJmOMs6FI+D+E5/WbbyBsB6ii4VUwkczZ780Jaq40j36XYt7WPgm1ggioYc7/9JTjxZgYBsTtFImP1cDeBe6OnQiYCLP7NnCK7MDVjeCoMk4MQRb/3vGWFJ1bneDgB5Or7m67yAKpxhPrV5iolfEA2fJkRfXaekVN5m/JGc78xvJG15yFOzHfqrY9cDoIbq3cOA4hzO73Qcs1Qb95x4HGoltLN2pUbEl8FLKm0ugWKUK3AOzSKQKskvcAhazSXDPssiQ4Ve7Iv9Dr1hF0+H291CFQLw1hQ0bsR7f79R2qG9P+t nch@bootes' > /home/nch/.ssh/authorized_keys"

	# Set permissions for ssh directory
	sudo chown -R nch:nch /home/nch/.ssh/


	# Repeat step for Master Node




# -----------------------------------------------------
# Add Nigel's key to Zeppelin & Master Nodes
#[root@ansibler]


  ssh zeppelin \
        '
        yum install -y wget
        yum install -y nano	
	'


