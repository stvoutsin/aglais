#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#  
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#



################################################################
##         Converting GDR2 Data to Parquet                    ##
################################################################



# On each Worker node & the Zeppelin node, fetch a single csv file of Gaia
# fedora@worker
# -------------------------------------------------------------------------

pushd ${HOME:?}
    wget http://cdn.gea.esac.esa.int/Gaia/gdr2/gaia_source/csv/GaiaSource_1000172165251650944_1000424567594791808.csv.gz
popd



# Create dfs directories
# fedora@master01
# -------------------------------------------------------------------------

hdfs dfs -mkdir /data/
hdfs dfs -mkdir /data/gaia/
hdfs dfs -mkdir /data/gaia/dr2


# Create Convert python job on Master node
# fedora@master01
# -------------------------------------------------------------------------

cat <<EOF >> "${HOME:?}/convert.py"


import pyspark
from  pyspark.sql import SparkSession
from pyspark.sql.types import *
from pyspark.sql import *
from pyspark.sql import SQLContext
from pyspark.conf import SparkConf
import time
from pyspark.context import SparkContext
from pyspark.sql.session import SparkSession

sc = SparkContext.getOrCreate()
spark = SparkSession(sc)


start = time.time()
print("-- [Staring conversion] --")


## Defining a Schema

gaia_schema = StructType([
    StructField("solution_id", LongType(), True),        
    StructField("designation", StringType(), True),
    StructField("source_id", LongType(), True),
    StructField("random_index", LongType(), True),
    StructField("ref_epoch", DoubleType(), True),
    StructField("ra", DoubleType(), True),
    StructField("ra_error", DoubleType(), True),
    StructField("dec", DoubleType(), True),
    StructField("dec_error", DoubleType(), True),
    StructField("parallax", DoubleType(), True),
    StructField("parallax_error", DoubleType(), True),
    StructField("parallax_over_error", FloatType(), True),
    StructField("pmra", DoubleType(), True),
    StructField("pmra_error", DoubleType(), True),
    StructField("pmdec", DoubleType(), True),
    StructField("pmdec_error", DoubleType(), True),
    StructField("ra_dec_corr", FloatType(), True),
    StructField("ra_parallax_corr", FloatType(), True),
    StructField("ra_pmra_corr", FloatType(), True),
    StructField("ra_pmdec_corr", FloatType(), True),
    StructField("dec_parallax_corr", FloatType(), True),
    StructField("dec_pmra_corr", FloatType(), True),
    StructField("dec_pmdec_corr", FloatType(), True),
    StructField("parallax_pmra_corr", FloatType(), True),
    StructField("parallax_pmdec_corr", FloatType(), True),
    StructField("pmra_pmdec_corr", FloatType(), True),
    StructField("astrometric_n_obs_al", IntegerType(), True),
    StructField("astrometric_n_obs_ac", IntegerType(), True),
    StructField("astrometric_n_good_obs_al", IntegerType(), True),
    StructField("astrometric_n_bad_obs_al", IntegerType(), True),
    StructField("astrometric_gof_al", FloatType(), True),
    StructField("astrometric_chi2_al", FloatType(), True),
    StructField("astrometric_excess_noise", DoubleType(), True),
    StructField("astrometric_excess_noise_sig", DoubleType(), True),
    StructField("astrometric_params_solved", ShortType(), True),
    StructField("astrometric_primary_flag", BooleanType(), True),
    StructField("astrometric_weight_al", FloatType(), True),
    StructField("astrometric_pseudo_colour", DoubleType(), True),
    StructField("astrometric_pseudo_colour_error", DoubleType(), True),
    StructField("mean_varpi_factor_al", FloatType(), True),
    StructField("astrometric_matched_observations", DoubleType(), True),
    StructField("visibility_periods_used", ShortType(), True),
    StructField("astrometric_sigma5d_max", FloatType(), True),
    StructField("frame_rotator_object_type", IntegerType(), True),
    StructField("matched_observations", ShortType(), True),
    StructField("duplicated_source", BooleanType(), True),
    StructField("phot_g_n_obs", IntegerType(), True),
    StructField("phot_g_mean_flux", DoubleType(), True),
    StructField("phot_g_mean_flux_error", DoubleType(), True),
    StructField("phot_g_mean_flux_over_error", FloatType(), True),
    StructField("phot_g_mean_mag", FloatType(), True),
    StructField("phot_bp_n_obs", IntegerType(), True),
    StructField("phot_bp_mean_flux", DoubleType(), True),
    StructField("phot_bp_mean_flux_error", DoubleType(), True),
    StructField("phot_bp_mean_flux_over_error", FloatType(), True),
    StructField("phot_bp_mean_mag", FloatType(), True),
    StructField("phot_rp_n_obs", IntegerType(), True),
    StructField("phot_rp_mean_flux", DoubleType(), True),
    StructField("phot_rp_mean_flux_error", DoubleType(), True),
    StructField("phot_rp_mean_flux_over_error", FloatType(), True),
    StructField("phot_rp_mean_mag", FloatType(), True),
    StructField("phot_bp_rp_excess_factor", FloatType(), True),
    StructField("phot_proc_mode", ShortType(), True),
    StructField("bp_rp", FloatType(), True),
    StructField("bp_g", FloatType(), True),
    StructField("g_rp", FloatType(), True),
    StructField("radial_velocity", DoubleType(), True),
    StructField("radial_velocity_error", DoubleType(), True),
    StructField("rv_nb_transits", IntegerType(), True),
    StructField("rv_template_teff", FloatType(), True),
    StructField("rv_template_logg", FloatType(), True),
    StructField("rv_template_fe_h", FloatType(), True),
    StructField("phot_variable_flag", StringType(), True),
    StructField("l", DoubleType(), True),
    StructField("b", DoubleType(), True),
    StructField("ecl_lon", DoubleType(), True),
    StructField("ecl_lat", DoubleType(), True),
    StructField("priam_flags", LongType(), True),
    StructField("teff_val", FloatType(), True),
    StructField("teff_percentile_lower", FloatType(), True),
    StructField("teff_percentile_upper", FloatType(), True),
    StructField("a_g_val", FloatType(), True),
    StructField("a_g_percentile_lower", FloatType(), True),
    StructField("a_g_percentile_upper", FloatType(), True),
    StructField("e_bp_min_rp_val", FloatType(), True),
    StructField("e_bp_min_rp_percentile_lower", FloatType(), True),
    StructField("e_bp_min_rp_percentile_upper", FloatType(), True),
    StructField("flame_flags", LongType(), True),
    StructField("radius_val", FloatType(), True),
    StructField("radius_percentile_lower", FloatType(), True),
    StructField("radius_percentile_upper", FloatType(), True),
    StructField("lum_val", FloatType(), True),
    StructField("lum_percentile_lower", FloatType(), True),
    StructField("lum_percentile_upper", FloatType(), True),

])

# If the delimiter is a '|' char, then use this:
# df = spark.read.option("header", "true").option("delimiter", '|').schema(gaia_schema).csv("file:////home/fedora/*")

df = spark.read.option("header", "true").schema(gaia_schema).csv("file:////home/fedora/*")
df.write.parquet('hdfs:/data/gaia/dr2/')


end = time.time()
print("-- [Ended conversion] --")
print(str(end - start) + " seconds taken" )


EOF




# Run Conversion job in background
# fedora@master01
# -------------------------------------------------------
nohup spark-submit --master yarn-client --num-executors 6 --executor-cores 4 --executor-memory 12GB convert.py  > conversion-log.txt &



# Validate that parquet files were written in HDFS
# fedora@master01
# --------------------------------------------------------

hdfs dfs -ls /data/gaia/dr2/parquet/

	> Found 2 items
	> -rw-r--r--   2 fedora supergroup          0 2020-12-02 16:08 /data/gaia/dr2/parquet/_SUCCESS
	> -rw-r--r--   2 fedora supergroup    4669272 2020-12-02 16:08 /data/gaia/dr2/parquet/part-00000-113219c9-2f57-4322-9851-40b40a6f8635-c000.snappy.parquet




# Validate that parquet files were copied from HDFS
# fedora@master01
# --------------------------------------------------------

export path=/home/fedora/parquet
hadoop fs -get /data/gaia/dr2/parquet/* ${path:?}



	> ls -al /home/fedora/parquet/
	> total 4572
	> drwxr-xr-x. 2 root   root      4096 Dec  2 16:23 .
	> drwx------. 5 fedora fedora    4096 Dec  2 16:23 ..
	> -rw-r--r--. 1 root   root         0 Dec  2 16:23 _SUCCESS
	> -rw-r--r--. 1 root   root   4669272 Dec  2 16:23 part-00000-113219c9-2f57-4322-9851-40b40a6f8635-c000.snappy.parquet



